<div style="font-family:Arial, sans-serif;padding:20px;max-width:100%;width:100%;overflow-x:auto"><div style="margin-bottom:20px"><h2 style="font-size:24px;margin-bottom:15px;color:#333">Model Comparison</h2><p style="font-size:17px;line-height:1.5">Comparison of machine learning models evaluated on the iceberg order dataset</p></div><div style="margin-top:30px;width:100%"><div style="display:flex;flex-direction:column;gap:10px;margin-bottom:25px"><div style="display:flex;align-items:center;height:40px"><div style="width:150px;font-weight:bold;font-size:16px">LogisticRegression</div><div style="height:30px;border-radius:3px;display:flex;align-items:center;justify-content:center;color:white;font-weight:bold;width:345px;background-color:#9c59b6">69%</div></div><div style="display:flex;align-items:center;height:40px"><div style="width:150px;font-weight:bold;font-size:16px">XGBoost</div><div style="height:30px;border-radius:3px;display:flex;align-items:center;justify-content:center;color:white;font-weight:bold;width:335px;background-color:#3498db">67%</div></div><div style="display:flex;align-items:center;height:40px"><div style="width:150px;font-weight:bold;font-size:16px">LightGBM</div><div style="height:30px;border-radius:3px;display:flex;align-items:center;justify-content:center;color:white;font-weight:bold;width:335px;background-color:#e67e22">67%</div></div><div style="display:flex;align-items:center;height:40px"><div style="width:150px;font-weight:bold;font-size:16px">RandomForest</div><div style="height:30px;border-radius:3px;display:flex;align-items:center;justify-content:center;color:white;font-weight:bold;width:330px;background-color:#2ecc71">66%</div></div></div></div><table style="width:100%;border-collapse:collapse;margin-top:20px;font-size:16px"><thead><tr><th style="background-color:#4a90e2;color:white;padding:12px;text-align:left;border:1px solid #ddd;font-size:17px;font-weight:bold">Model</th><th style="background-color:#4a90e2;color:white;padding:12px;text-align:left;border:1px solid #ddd;font-size:17px;font-weight:bold">Description</th><th style="background-color:#4a90e2;color:white;padding:12px;text-align:left;border:1px solid #ddd;font-size:17px;font-weight:bold">Parameters</th><th style="background-color:#4a90e2;color:white;padding:12px;text-align:left;border:1px solid #ddd;font-size:17px;font-weight:bold">Strengths</th><th style="background-color:#4a90e2;color:white;padding:12px;text-align:left;border:1px solid #ddd;font-size:17px;font-weight:bold">Limitations</th></tr></thead><tbody><tr><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><strong>LogisticRegression</strong></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">Linear model for binary classification</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><ul style="margin:0;padding-left:20px"><li>penalty=&#x27;elasticnet&#x27;</li><li>C=0.01</li><li>solver=&#x27;saga&#x27;</li><li>max_iter=1000</li><li>l1_ratio=0.5</li><li>train_size=2</li></ul></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- Simple and interpretable<br/>- Fast training and inference<br/>- Less prone to overfitting</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- Cannot capture non-linear relationships<br/>- Lower performance ceiling<br/>- Feature engineering more important</td></tr><tr style="background-color:#e8f4f8"><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><strong>XGBoost</strong></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">Gradient boosted trees with regularization</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><ul style="margin:0;padding-left:20px"><li>eval_metric=&#x27;error@0.5&#x27;</li><li>learning_rate=0.03</li><li>n_estimators=250</li><li>max_depth=4</li><li>gamma=0.2</li><li>subsample=1.0</li><li>colsample_bytree=0.8</li><li>reg_alpha=0.2</li><li>reg_lambda=2</li><li>train_size=2</li></ul></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- High prediction accuracy<br/>- Handles imbalanced data well<br/>- Efficient implementation</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- More prone to overfitting than RF<br/>- Requires more hyperparameter tuning<br/>- Less interpretable</td></tr><tr><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><strong>LightGBM</strong></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">Gradient boosting framework that uses tree-based algorithms</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><ul style="margin:0;padding-left:20px"><li>objective=&#x27;regression&#x27;</li><li>learning_rate=0.05</li><li>n_estimators=100</li><li>max_depth=4</li><li>num_leaves=31</li><li>min_sum_hessian_in_leaf=10</li><li>extra_trees=True</li><li>min_data_in_leaf=100</li><li>feature_fraction=1.0</li><li>bagging_fraction=0.8</li><li>lambda_l1=2</li><li>lambda_l2=0</li><li>min_gain_to_split=0.1</li><li>train_size=2</li></ul></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- Faster training speed<br/>- Lower memory usage<br/>- Better accuracy with categorical features</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- Can overfit on small datasets<br/>- Less common in production environments<br/>- Newer with less community support</td></tr><tr><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><strong>RandomForest</strong></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">Ensemble of decision trees using bootstrap samples</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5"><ul style="margin:0;padding-left:20px"><li>n_estimators=500</li><li>criterion=&#x27;log_loss&#x27;</li><li>max_depth=4</li><li>min_samples_split=7</li><li>min_samples_leaf=3</li><li>train_size=2</li></ul></td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- Handles non-linearity well<br/>- Robust to outliers<br/>- Native feature importance</td><td style="padding:12px;border:1px solid #ddd;vertical-align:top;font-size:16px;line-height:1.5">- May overfit on noisy data<br/>- Less interpretable than single trees<br/>- Memory intensive for large datasets</td></tr></tbody></table><div style="background-color:#f9f9f9;border:1px solid #ddd;border-radius:5px;padding:20px;margin-top:25px;width:100%"><div style="font-weight:bold;margin-bottom:15px;font-size:18px">Evaluation Metrics Used:</div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>Accuracy:</strong></span><span>Overall correctness of predictions</span></div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>Precision:</strong></span><span>Proportion of positive identifications that were correct</span></div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>Recall:</strong></span><span>Proportion of actual positives that were identified correctly</span></div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>F1 Score:</strong></span><span>Harmonic mean of precision and recall</span></div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>F-beta Score:</strong></span><span>Weighted F-score with emphasis on precision (β=0.5) or recall (β=2.0)</span></div><div style="display:flex;justify-content:space-between;margin:8px 0;font-size:16px;line-height:1.4"><span><strong>Custom Metric:</strong></span><span>max_precision_optimal_recall_score - Maximizes precision with minimum recall threshold</span></div></div></div>